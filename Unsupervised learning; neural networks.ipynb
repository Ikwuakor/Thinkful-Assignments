{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "Neural Networks are one of the most popular and impactful branches of machine learning today. This is the very bleeding edge of data science, but it has historical roots. In this module we'll explore:\n",
    "\n",
    "+ The perceptron model\n",
    "+ Multi-level perceptrons and neural network structure\n",
    "+ How to use Neural Networks for supervised and unsupervised learning\n",
    "\n",
    "This will be just the beginning of neural networks, and we'll add resources to go deeper along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Perceptron\n",
    "\n",
    "Before we get into neural networks, we need to talk about perceptron models. Perceptron models will form the basis of Neural Networks. The models themselves are heavily indebted to linear regression which was one of the first models we covered.\n",
    "\n",
    "### Conceptual Basis\n",
    "\n",
    "Remember the initial specification for a linear regression?\n",
    "\n",
    "$$ y = \\alpha + \\beta X $$\n",
    "\n",
    "The other key aspect of linear regression is our cost function. In the linear regression context, we are trying to minimize the squared error terms. \n",
    "\n",
    "Perceptrons rely on that same linear specification but use it for a different purpose. Firstly, perceptrons are classifiers, at their core binary classifiers (though much like other methods there are ways to expand them to work with multiple classes). This takes our functional form and turns it into a rule to classify into groups A and B.\n",
    "\n",
    "$$ \\alpha + \\beta X \\geq 0 : A $$\n",
    "$$ \\alpha + \\beta X < 0 : B $$\n",
    "\n",
    "Here the $\\alpha$ is the _shift_ , a way of regularizing the boundary to zero. Then $\\beta$ is the _weight_ , which controls the influence of each variable in a linear fashion much like OLS.\n",
    "\n",
    "Recall in linear regression we minimize the error. In SVM the goal was to create the largest margin between our boundary and the nearest data points of each class. For Perceptron models, the cost we are trying to minimize is the sum of the output of our functional form from all misclasified examples. This can be thought of as minimizing the error for the classifier.  So if we create a boundary with errors, we take the absolute value of the misclasified observations and sum them together for our cost. Based on this cost function all boundries that correctly divide all data points into classes with no errors will have the same cost: zero.\n",
    "\n",
    "It's important to note that in this kind of simple perceptron the outcome is binary. A result is either in class A or class B with no probability given or gradient permitted. When working with perceptrons, it is common practice to invoke a curve with a gradient to it, meaning the prediction takes non-binary values between zero and one.\n",
    "\n",
    "The most common curve to use is called the _logistic function_ or _sigmoid curve_ because it gives a nice \"S\" or sigmoid shaped curve. The formula for that function is:\n",
    "\n",
    "$$ \\frac{1}{1+e^{-x}} $$\n",
    "\n",
    "![image.png](attachment:image.png 'sigmoid curve')\n",
    "\n",
    "Using this for perceptrons means outputting the value from our linear model into this function rather than simply using binary values for 0 if less than 0 and 1 if greater than 0. Allowing for continuous outputs from a perceptron will be valuable in allowing for more subtlety in our perceptron and thus in our neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptrons in Practice\n",
    "\n",
    "Now let's go through a perceptron in practice. To do so let's bring back the example from SVM: student test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame()\n",
    "\n",
    "test_data['test'] = [90, 100, 85, 93, 88, 100, 97, 92, 89, 84,\n",
    "                     55, 65, 75, 58, 69, 71, 72, 63, 70, 59]\n",
    "test_data['project'] = [100, 85, 98, 88, 87, 99, 99, 86, 89, 100,\n",
    "                        67, 71, 74, 73, 55, 59, 56, 72, 67, 72]\n",
    "test_data['pass'] = ['pass', 'pass', 'pass', 'pass', 'pass',\n",
    "                     'pass', 'pass', 'pass', 'pass', 'pass',\n",
    "                     'fail', 'fail', 'fail', 'fail', 'fail',\n",
    "                     'fail', 'fail', 'fail', 'fail', 'fail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uzi/.venv/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import Perceptron.\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Establish X and Y.\n",
    "X = test_data[['test', 'project']]\n",
    "Y = test_data['pass']\n",
    "\n",
    "# Establish Perceptron Model.\n",
    "# 10,000 iterations to ensure accuracy since data is non-normalized.\n",
    "# perceptron = Perceptron(n_iter=10000)\n",
    "### If running in your own environment on scikit-learn 0.21, run the line of code below instead:\n",
    "perceptron = Perceptron(max_iter=10000, tol=0, n_iter_no_change=10000)\n",
    "\n",
    "\n",
    "# Fit Perceptron.\n",
    "perceptron.fit(X, Y)\n",
    "\n",
    "# Get Parameters.\n",
    "print('Score: ' + str(perceptron.score(X, Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Let's use the same mesh we've used previously to create and show our perceptron border."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Establish a mesh for our plot.\n",
    "x_min, x_max = X.test.min() - 1, X.test.max() + 3\n",
    "y_min, y_max = X.project.min() - 1, X.project.max() + 3\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, .1),\n",
    "                     np.arange(y_min, y_max, .1))\n",
    "\n",
    "# Predict over that mesh.\n",
    "Z = (perceptron.predict(np.c_[xx.ravel(), yy.ravel()])=='pass')\n",
    "\n",
    "\n",
    "# Reshape the prediction to be plottable.\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the mesh.\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "\n",
    "# Plot our two scatters.\n",
    "plt.scatter(test_data.project[0:10], test_data.test[0:10], marker='x')\n",
    "plt.scatter(test_data.project[10:20], test_data.test[10:20], marker='o')\n",
    "\n",
    "# Aesthetics.\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xlabel('Project Grade')\n",
    "plt.ylabel('Test Grade')\n",
    "plt.title('Passing Grades Perceptron Example')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Now, this is clearly different from the optimal SVM model. The simplicity of the perceptron cost function means that this is totally satisfactory to the model: every point is correctly classified so the cost is zero, and the perceptron algorithm stops as soon as that condition is met. Until it meets that condition, however, it keeps trying new things to see if it can get a successful classifier.\n",
    "\n",
    "If all of this seems rather inefficient that's because it often is. That decision boundary looks inefficient to the human eye. It took a lot of iterations to get there. There are many techniques that are more useful on their own.\n",
    "\n",
    "However, here you should think of the decision tree. Decision trees are not always a great model on their own, but through boosting or random forest we were able to craft some of the most powerful models in machine learning. The same is true with the perceptron.\n",
    "\n",
    "That's because a neural network, when you get down to it, is just an ensemble of perceptrons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a neural network?\n",
    "Before we do anything more we need to talk. How's it going? You all right? Hopefully things are hard but not, you know, too hard. The sweet spot. Going on a tough hike but not climbing Everest. Maybe you've even seen a few of the signposts that say \"Everest, this way\" and wandered down those paths for a bit to see what was there. It's fun to live on the edge every now and again. But we haven't strayed far down any of those paths or pushed to too great a height too quickly.\n",
    "\n",
    "The point is, you shouldn't need oxygen.\n",
    "\n",
    "But now we're on to neural networks and, well, the air here can get a little thin.\n",
    "\n",
    "So first a few disclaimers.\n",
    "\n",
    "# Disclaimers\n",
    "+ We are going to stick to classical neural networks, occasionally giving hints towards more current, but less used, techniques.\n",
    "+ The math here is going to be very hand wavy. For most of you it's better that way. If you want the background math we will link to it when we can.\n",
    "+ Neural networks is an evolving field. If you really love this you should consider getting a PhD in it or at least + keeping up with the latest papers from the field and industry.\n",
    "+ Most data science jobs come nowhere near pushing the bounds of neural networks. If you want to do that, there is a smaller list of places you'll want to apply, and again, a PhD might be necessary for accessing those teams.\n",
    "+ Some of the new new here is still controversial. Particularly some of the people who are more classical statisticians have issues with neural networks and deep learning, which are a black box and initially it wasn't even really understood why they worked so well in some circumstances. The tide seems to be moving against this perspective, but it is definitely out there.\n",
    "+ If you want more [this book](http://www.deeplearningbook.org/) is fantastic.\n",
    "\n",
    "Ok, now we can actually talk about what a neural network is. To do that, we have to talk about the brain.\n",
    "\n",
    "# Your brain, neural networks, and you\n",
    "As a human being, you have a brain. And quite a nice one by the looks of it. Well done for making it this far in the course.\n",
    "\n",
    "Your brain, and your whole nervous system, is made up of neurons and axons. Bear with us on this as some of the biology here will be oversimplified, but these simplifications are perpetuated in the machine learning algorithms we're actually talking about, so they are good to know.\n",
    "\n",
    "Neurons can be thought of as the information processors of the brain. They react to signals and create responses. Axons connect neurons to each other. A human brain is made up of billions of neurons linked to each other through a complex web of axons. Information passes through several neurons in response to input or stimulus.\n",
    "\n",
    "This is the basis of neural networks, the machine learning algorithm. Sometimes these are referred to as \"artificial neural networks\" so as to differentiate them from the biological variety. Sometimes that differentiation is noted because one is a computer program and the other is a vital organ.\n",
    "\n",
    "# Artificial neural networks\n",
    "To explain what an artificial neural network is, let's return to the perceptron.\n",
    "\n",
    "![](https://curricula.thinkful.com/curricula/8bc40dfb-3bb7-4aa5-87d5-de71ef153263/dsbc-neural-networks-v1/assets2/what_is_a_neural_network/perceptron_single.jpeg 'single preceptron diagram')\n",
    "\n",
    "The perceptron model takes in some data and generates a response. Now, previously we mentioned that this is usually a poorly performing model. We've dealt with this problem in the past using ensemble techniques like bagging which gave us random forests. Let's keep that concept of ensemble modeling and have many perceptrons in our model.\n",
    "\n",
    "![](https://curricula.thinkful.com/curricula/8bc40dfb-3bb7-4aa5-87d5-de71ef153263/dsbc-neural-networks-v1/assets2/what_is_a_neural_network/single_layer.jpeg 'single-layered model')\n",
    "\n",
    "Now we're getting closer to a neural network. But let's also recall another ensemble concept: boosting. That's when we take the output from one model and use it as the input for another. Let's use boosting to feed the results from one part of our model into the next part.\n",
    "\n",
    "![](https://curricula.thinkful.com/curricula/8bc40dfb-3bb7-4aa5-87d5-de71ef153263/dsbc-neural-networks-v1/assets2/what_is_a_neural_network/two_layer.jpeg 'two-layerd model')\n",
    "\n",
    "Now that is a serious neural network. A few things to note before we move on and start seeing how to actually implement these models.\n",
    "\n",
    "Firstly, the columns of perceptrons are called layers. Neural networks have layers much like certain pastries, aromatic bulbs, or [green monsters](https://www.youtube.com/watch?v=_bMcXVe8zIs). They can be single layer or multi layered. The first layer is called the visible layer.\n",
    "\n",
    "Any layers after that first layer are called hidden layers. These are features built on features. They are called hidden because you're not directly observing their inputs or outputs. They serve as one way of getting around linearity of the initial perceptron boundary. We now have a function of a function, giving greater detail and subtlety to our model.\n",
    "\n",
    "Now, this model has many many perceptrons, so how are the perceptrons different from one another? Surely we're not just doing the same thing again and again and again, right? To answer that, recall the initial perceptron. Each variable input into the model was given a weight. Here our different perceptrons give different variables different sets of weights. When done at a mass scale (it's not uncommon for a layer to be hundreds or thousands of perceptrons wide) they combine to overcome the initial assumption of linearity, allowing for a model where different combinations of variables have hugely different effects. This ultimately generates a very powerful model.\n",
    "\n",
    "All of the networks we've shown here are what are called \"fully connected\". Every perceptron in one layer links to every perceptron in the following layer. You can weight your perceptrons so that they are not fully connected or evenly balanced in their connections.\n",
    "\n",
    "That second image, the one with a single layer of perceptrons, is actually a simple, single layer neural network. Many-layered networks begin to enter into the realm of deep learning. Also of note is that direction was removed from our final image. The way the layers feed back into each other ends up being a key differentiator in different styles of neural network, so data does not always flow in one direction.\n",
    "\n",
    "We'll cover all of this in more detail as we get into implementations, but you should now have a conceptual understanding of what a neural network is going to look like. Let's build one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "We're ready to build our first neural network. We will have multiple features we feed into our model, each of which will go through a set of perceptron models to arrive at a response which will be trained to our output.\n",
    "\n",
    "Like many models we've covered, this can be used as both a regression or classification model.\n",
    "\n",
    "First, we need to load our dataset. For this example we'll use The Museum of Modern Art in New York's public dataset on their collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "artworks = pd.read_csv('https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/Artworks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'Artist', 'ConstituentID', 'ArtistBio', 'Nationality',\n",
       "       'BeginDate', 'EndDate', 'Gender', 'Date', 'Medium', 'Dimensions',\n",
       "       'CreditLine', 'AccessionNumber', 'Classification', 'Department',\n",
       "       'DateAcquired', 'Cataloged', 'ObjectID', 'URL', 'ThumbnailURL',\n",
       "       'Circumference (cm)', 'Depth (cm)', 'Diameter (cm)', 'Height (cm)',\n",
       "       'Length (cm)', 'Weight (kg)', 'Width (cm)', 'Seat Height (cm)',\n",
       "       'Duration (sec.)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artworks.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "We'll also do a bit of data processing and cleaning, selecting columns of interest and converting URL's to booleans indicating whether they are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Select Columns.\n",
    "artworks = artworks[['Artist', 'Nationality', 'Gender', 'Date', 'Department',\n",
    "                    'DateAcquired', 'URL', 'ThumbnailURL', 'Height (cm)', 'Width (cm)']]\n",
    "\n",
    "# Convert URL's to booleans.\n",
    "artworks['URL'] = artworks['URL'].notnull()\n",
    "artworks['ThumbnailURL'] = artworks['ThumbnailURL'].notnull()\n",
    "\n",
    "# Drop films and some other tricky rows.\n",
    "artworks = artworks[artworks['Department']!='Film']\n",
    "artworks = artworks[artworks['Department']!='Media and Performance Art']\n",
    "artworks = artworks[artworks['Department']!='Fluxus Collection']\n",
    "\n",
    "# Drop missing data.\n",
    "artworks = artworks.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Date</th>\n",
       "      <th>Department</th>\n",
       "      <th>DateAcquired</th>\n",
       "      <th>URL</th>\n",
       "      <th>ThumbnailURL</th>\n",
       "      <th>Height (cm)</th>\n",
       "      <th>Width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Otto Wagner</td>\n",
       "      <td>(Austrian)</td>\n",
       "      <td>(Male)</td>\n",
       "      <td>1896</td>\n",
       "      <td>Architecture &amp; Design</td>\n",
       "      <td>1996-04-09</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>48.6000</td>\n",
       "      <td>168.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Christian de Portzamparc</td>\n",
       "      <td>(French)</td>\n",
       "      <td>(Male)</td>\n",
       "      <td>1987</td>\n",
       "      <td>Architecture &amp; Design</td>\n",
       "      <td>1995-01-17</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>40.6401</td>\n",
       "      <td>29.8451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emil Hoppe</td>\n",
       "      <td>(Austrian)</td>\n",
       "      <td>(Male)</td>\n",
       "      <td>1903</td>\n",
       "      <td>Architecture &amp; Design</td>\n",
       "      <td>1997-01-15</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>34.3000</td>\n",
       "      <td>31.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernard Tschumi</td>\n",
       "      <td>()</td>\n",
       "      <td>(Male)</td>\n",
       "      <td>1980</td>\n",
       "      <td>Architecture &amp; Design</td>\n",
       "      <td>1995-01-17</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>50.8000</td>\n",
       "      <td>50.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emil Hoppe</td>\n",
       "      <td>(Austrian)</td>\n",
       "      <td>(Male)</td>\n",
       "      <td>1903</td>\n",
       "      <td>Architecture &amp; Design</td>\n",
       "      <td>1997-01-15</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>38.4000</td>\n",
       "      <td>19.1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Artist Nationality  Gender  Date             Department  \\\n",
       "0               Otto Wagner  (Austrian)  (Male)  1896  Architecture & Design   \n",
       "1  Christian de Portzamparc    (French)  (Male)  1987  Architecture & Design   \n",
       "2                Emil Hoppe  (Austrian)  (Male)  1903  Architecture & Design   \n",
       "3           Bernard Tschumi          ()  (Male)  1980  Architecture & Design   \n",
       "4                Emil Hoppe  (Austrian)  (Male)  1903  Architecture & Design   \n",
       "\n",
       "  DateAcquired   URL  ThumbnailURL  Height (cm)  Width (cm)  \n",
       "0   1996-04-09  True          True      48.6000    168.9000  \n",
       "1   1995-01-17  True          True      40.6401     29.8451  \n",
       "2   1997-01-15  True          True      34.3000     31.8000  \n",
       "3   1995-01-17  True          True      50.8000     50.8000  \n",
       "4   1997-01-15  True          True      38.4000     19.1000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artworks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Building a Model\n",
    "\n",
    "Now, let's see if we can use multi-layer perceptron modeling (or \"MLP\") to see if we can classify the department a piece should go into using everything but the department name.\n",
    "\n",
    "Before we import MLP from SKLearn and establish the model we first have to ensure correct typing for our data and do some other cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Artist           object\n",
       "Nationality      object\n",
       "Gender           object\n",
       "Date             object\n",
       "Department       object\n",
       "DateAcquired     object\n",
       "URL                bool\n",
       "ThumbnailURL       bool\n",
       "Height (cm)     float64\n",
       "Width (cm)      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data types.\n",
    "artworks.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DateAcquired` column is an object. Let's transform that to a datetime object and add a feature for just the year the artwork was acquired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artworks['DateAcquired'] = pd.to_datetime(artworks.DateAcquired)\n",
    "artworks['YearAcquired'] = artworks.DateAcquired.dt.year\n",
    "artworks['YearAcquired'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Let's do some more miscellaneous cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Remove multiple nationalities, genders, and artists.\n",
    "artworks.loc[artworks['Gender'].str.contains('\\) \\('), 'Gender'] = '\\(multiple_persons\\)'\n",
    "artworks.loc[artworks['Nationality'].str.contains('\\) \\('), 'Nationality'] = '\\(multiple_nationalities\\)'\n",
    "artworks.loc[artworks['Artist'].str.contains(','), 'Artist'] = 'Multiple_Artists'\n",
    "\n",
    "# Convert dates to start date, cutting down number of distinct examples.\n",
    "artworks['Date'] = pd.Series(artworks.Date.str.extract(\n",
    "    '([0-9]{4})', expand=False))[:-1]\n",
    "\n",
    "# Final column drops and NA drop.\n",
    "X = artworks.drop(['Department', 'DateAcquired', 'Artist', 'Nationality', 'Date'], 1)\n",
    "\n",
    "# Create dummies separately.\n",
    "artists = pd.get_dummies(artworks.Artist)\n",
    "nationalities = pd.get_dummies(artworks.Nationality)\n",
    "dates = pd.get_dummies(artworks.Date)\n",
    "\n",
    "# Concat with other variables, but artists slows this wayyyyy down so we'll keep it out for now\n",
    "X = pd.get_dummies(X, sparse=True)\n",
    "X = pd.concat([X, nationalities, dates], axis=1)\n",
    "\n",
    "Y = artworks.Department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uzi/.venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(1000,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alright! We've done our prep, let's build the model.\n",
    "# Neural networks are hugely computationally intensive.\n",
    "# This may take several minutes to run.\n",
    "\n",
    "# Import the model.\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Establish and fit the model, with a single, 1000 perceptron layer.\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(1000,))\n",
    "mlp.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7970696105376364"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drawings & Prints        0.622800\n",
       "Photography              0.225837\n",
       "Architecture & Design    0.113383\n",
       "Painting & Sculpture     0.033578\n",
       "Media and Performance    0.004403\n",
       "Name: Department, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()/len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uzi/.venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/home/uzi/.venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/uzi/.venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/home/uzi/.venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.64897284, 0.73077807, 0.65241969, 0.65502344, 0.62286266])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(mlp, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Now we got a lot of information from all of this. Firstly we can see that the model seems to overfit, though there is still so remaining performance when validated with cross validation. This is a feature of neural networks that aren't given enough data for the number of features present. **Neural networks, in general, like _a lot_ of data**. You may also have noticed something about neural networks: **they can take a long time to run**. Try increasing the layer size by adding a zero. Feel free to interrupt the kernel if you don't have time...\n",
    "\n",
    "Also note that we created bools for artist's name but left them out. Both of the above points are the reason for that. It would take much longer to run and it would be much more prone to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Model parameters\n",
    "\n",
    "Now, before we move on and let you loose with some tasks to work on the model, let's go over the parameters.\n",
    "\n",
    "We included one parameter: `hidden_layer_sizes`. Remember in the previous lesson, when we talked about layers in a neural network. This tells us how many and how big to make our layers. Pass in a tuple that specifies each layer's size. Our network is 1000 neurons wide and one layer. (100, 4, ) would create a network with two layers, one 100 wide and the other 4.\n",
    "\n",
    "How many layers to include is determined by two things: computational resources and cross validation searching for convergence. It's generally less than the number of input variables you have.\n",
    "\n",
    "You can also set an `alpha`. Neural networks like this use a regularization parameter that penalizes large coefficients just like we discussed in the advanced regression section. Alpha scales that penalty.\n",
    "\n",
    "Lastly, we'll discuss the activation function. The activation function determines whether the output from an individual perceptron is binary or continuous. By default this is a 'relu', or 'rectified linear unit function' function. In the exercise we went through earlier we used this binary function, but we discussed the _sigmoid_ as a reasonable alternative. The _sigmoid_ (called 'logistic' by SKLearn because it's a 'logistic sigmoid function') allows for continuous variables between 0 and 1, which allows for a more nuanced model. It does come at the cost of increased computational complexity.\n",
    "\n",
    "If you want to learn more about these, study [activation functions](https://en.wikipedia.org/wiki/Activation_function) and [multilayer perceptrons](https://en.wikipedia.org/wiki/Multilayer_perceptron). The [Deep Learning](http://www.deeplearningbook.org/) book referenced earlier goes into great detail on the linear algebra involved.\n",
    "\n",
    "You could also just test the models with cross validation. Unless neural networks are your specialty cross validation should be sufficient.\n",
    "\n",
    "For the other parameters and their defaults, check out the [MLPClassifier documentation](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drill: Playing with layers\n",
    "\n",
    "Now it's your turn. Using the space below, experiment with different hidden layer structures. You can try this on a subset of the data to improve runtime. See how things vary. See what seems to matter the most. Feel free to manipulate other parameters as well. It may also be beneficial to do some real feature selection work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6227996801205982"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here. Experiment with hidden layers to build your own model.\n",
    "X = artworks.drop(['Department', 'DateAcquired', 'Artist', 'Nationality', 'Date'], 1)\n",
    "X = pd.get_dummies(X, sparse=True)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,5))\n",
    "mlp.fit(X, Y)\n",
    "mlp.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62277678, 0.62277678, 0.62277678, 0.6228054 , 0.62286266])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(mlp, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
